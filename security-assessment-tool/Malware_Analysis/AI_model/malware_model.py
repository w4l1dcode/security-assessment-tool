from keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from sklearn.utils import compute_class_weight
from sklearn import metrics
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Folder with images (dataset)
path_root = 'data_collection/malimg_dataset/malimg_dataset_subdir_imgs'

# ImageDataGenerator      Iterator
# flow_from_directory     Identifies classes automatically from the folder name
# directory               The path to parent directory containing sub-directories (class, label) with images
# target_size=(64,64)     Resizes images to 64x64
# batch_size              Divides dataset into batches/groups of 10000 images
batches = ImageDataGenerator().flow_from_directory(directory=path_root, target_size=(64, 64), batch_size=10000)

# batches.class_indices   Maps folder/class names to their corresponding indices (0 to class 1 etc.)
for malware_class, index in batches.class_indices.items():
    print(malware_class, ":", index)

# Generate a batch of images and labels
imgs, labels = next(batches)  # next to go through all elements in batches
print(f"\nShape of images batch: {imgs.shape}")  # batch_size, width, length, depth
print(f"Shape of labels batch: {labels.shape}")  # batch_size, number of classes


# Analyse the partition of data in % with a barplot
def barplot_data_partition():
    classes = batches.class_indices.keys()
    perc = (sum(labels) / labels.shape[0]) * 100
    plt.xticks(rotation='vertical')
    plt.bar(classes, perc)
    plt.gcf().subplots_adjust(bottom=0.3)  # Adjust the bottom margin to make room for rotated labels
    plt.savefig('AI_model/barplot_data_partition.png', bbox_inches='tight')
    plt.show()


barplot_data_partition()  # Dataset is quite unbalanced, with many malwares in classes 2 (Allaple.A) and 3 (Allaple.L).

# Splits the data into a training set (70%) and a testing set (30%)
X_train, X_test, y_train, y_test = train_test_split(imgs / 255., labels, test_size=0.3)
# Splits the testing set into a validation set (15%) and a new testing set (15%)
X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5)
print("\nX train shape:", X_train.shape, "\t\tY train shape:", y_train.shape)
print("X validation shape:", X_val.shape, "\tY validation shape:", y_val.shape)
print("X test shape:", X_test.shape, "\t\tY test shape:", y_test.shape, "\n")

# Building Convolutional Neural Network (CNN) model
num_classes = 25


def create_model():
    model = Sequential()

    model.add(Conv2D(30, kernel_size=(3, 3), activation='relu', input_shape=(64, 64, 3)))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Conv2D(15, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    model.add(Dropout(0.25))

    model.add(Flatten())
    model.add(Dense(128, activation='relu'))

    model.add(Dropout(0.5))

    model.add(Dense(50, activation='relu'))
    model.add(Dense(num_classes, activation='softmax'))

    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model


malware_model = create_model()
malware_model.summary()

y_train_new = np.argmax(y_train, axis=1)  # Extract class for each sample in y_train

# Compute the class weights based on the number of samples in each class
class_weights = compute_class_weight(class_weight="balanced", classes=np.unique(y_train_new), y=y_train_new)
class_weights = dict(zip(np.unique(y_train_new), class_weights))
print("\nComputed class weights.")
for class_number, weight in class_weights.items():
    print(f"Class {class_number}: {weight}")

# Train and validate model using the computed class weights
print("\nTraining and validating model using the computed class weights.")
malware_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, class_weight=class_weights)

# Save the model in current directory
malware_model.save('AI_model/malware_model_t.h5')  # Renamed to prevent accidentally overwriting

scores = malware_model.evaluate(X_test, y_test)
print('Final CNN accuracy: ', scores[1], "\n")

# Evaluate performance of the model using a confusion matrix as a heatmap
y_pred_prob = malware_model.predict(X_test, verbose=0)  # Predict class probabilities of samples in X_test
y_pred = np.argmax(y_pred_prob, axis=1)  # Selects class with the highest probability as the predicted class
y_test2 = np.argmax(y_test, axis=1)  # Extract the true classes of the samples in X_test
c_matrix = metrics.confusion_matrix(y_test2, y_pred)


def confusion_matrix(matrix, classes, figsize=(10, 7), fontsize=14):  # Create heatmap of the confusion matrix
    df_cm = pd.DataFrame(
        matrix, index=classes, columns=classes,
    )
    plt.gcf().subplots_adjust(bottom=0.3)  # Adjust the bottom margin to make room for rotated labels
    plt.figure(figsize=figsize)
    try:
        heatmap = sns.heatmap(df_cm, annot=True, fmt="d")
    except ValueError:
        raise ValueError("Confusion matrix values must be integers.")
    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)
    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)
    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.savefig('AI_model/confusion_matrix_t.png', bbox_inches='tight')  # Renamed to prevent accidentally overwriting
    plt.show()


class_names = batches.class_indices.keys()
confusion_matrix(c_matrix, class_names, figsize=(20, 7), fontsize=14)
